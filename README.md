# 2017BDCI-360搜索：AlphaGo之后“人机大战”Round 2 ——机器写作与人类写作的巅峰对决

## 赛题描述
如果说AlphaGo和人类棋手的对决拉响了“人机大战”的序曲，在人类更为通识的写作领域，即将上演更为精彩的机器写作和人类写作的对决。人类拥有数万年的书写历史，人类写作蕴藏无穷的信息、情感和思想。但随着深度学习、自然语言处理等人工智能技术发展，机器写作在语言组织、语法和逻辑处理方面几乎可以接近人类水平。360搜索智能写作助手也在此背景下应运而生。
          本次CCF大数据和人工智能大赛上，360搜索智能写作助手（机器写作）和人类写作将狭路相逢，如何辨别出一篇文章是通过庞大数据算法训练出来的机器写作的，还是浸染漫长书写历史的人类创作的？我们拭目以待！
          本次赛题任务：挑战者能够设计出优良的算法模型从海量的文章中区分出文章是机器写作还是人类写作。

## 任务描述


## 题目分析
1. 特征：
	- 题目：
	- 段落：

2. 样本：
	- 自行创建训练数据的负样本
		+ 每个样本只是给了用户当时所在的店铺，可以作为训练正样本
		+ 此时所有的其他的店铺都可以作为负样本
		+ 需要用最合理的方法生成自己的负样本。提高成绩
	- 给定：
		+ 2017年8月份的100家商场的详细数据
		+ 用户定位行为、商场内店铺、。。。
		+ 脱敏：匿名处理、有偏采样、过滤等措施
3. 预测：根据用户所处位置和WiFi等信息，判断用户所在的店铺
4. 挑战：
	- 外部数据：不允许使用
	- A榜：每天2次
	- B榜：每天1次，每天0点测评，显示最后提交的文件结果
	- 同一个用户的记录里面，存在相同的wifi，这是真实存在的，需要预处理
	- 同一个用户在同一家店铺里面发生行为，经纬度定位应该是不一样的，因为存在多种因素干扰
	-
5. 评价：采用2017年9月份的数据进行检测
	- 预测正确：给出的shop_id与标准答案相同
	- 准确率 = 预测正确样本总数 / 总样本数
6. 提交：
	- 提交格式：
	|  Field | Type | Description | Note |
	| - | :-: | :-: | :-: |
	| row_id | String | 测试数据ID | |
	| shop_id | String | 商铺ID | 算法的结果 |


## 数据集
1. 训练集：


2. 测试集：

	- A榜B榜格式相同，只是选取的时间不同，A是9月份第一周数据，B是9月份第二周数据

	| Field | Type | Description | Note |
	| - | :-: |  :-: | :-: |
	| row_id | String | 测试数据ID | |
	| user_id | String |  用户ID | 已脱敏，并和训练数据保持一致 |
	| mall_id | String | 商场ID | 已脱敏，并和训练数据保持一致 |
	| time_stamp | String | 行为时间戳 | 粒度为10分钟级别。例如：2017-08-06 21:20 |
	| longitude | Double | 行为发生时位置-精度 | 已脱敏，但相对距离依然可信 |
	| latitude | Double | 行为发生时位置-纬度 | 已脱敏，但相对距离依然可信 |
	| wifi_infos | String | 行为发生时Wifi环境，包括bssid（wifi唯一识别码），signal（强度），flag（是否连接） | `b_6396480|-67|false;b_41124514|-86|false;b_28723327|-90|false;` |

## 思路
0. 搜索技术
    - 爬虫
    - 页面筛选
    - 索引
    - Query理解
    - 检索模型
    - 搜索排序
    - 链接分析
    - 自然语言处理
    - 分布式系统
    - 核心：
        - 系统：大规模分布式系统，支撑大规模的数据处理容量和在线查询负载
        - 数据：数据处理和挖掘能力
        - 算法：搜索相关性排序，查询分析，分类，等等
    - 赛题目的：
        - 主要是为了区分网上的文本
        - 模型的鲁棒性：能否能抗压
        - 速度：
        - 性能：能否多用CPU，少用昂贵的GPU
1. 初步筛选
	- 使用网上公开的大规模语料训练词向量word2vec-api
	- 使用CNN进行文本分类
	- 步骤：
		+ 分词
			* 只保留汉字
			* jieba分词
			* 分词之后再去停用词 和 空格，但保留原始符号分割效果
		+ word2vec
			* 其实最好效果，应该是把train和test都作为词库输入给word2vec
			* 将分词的结果直接输入给word2vec，并保存产生的model
		+ padding
			* 取每句话词向量长度为500，也就是分词后取前500个词
			* 不足500的词向量值填补0
		+ 
		+ 

2. 官方提示：
	- 重视数据预处理：
	    - 对于常见停用词，噪声词的去噪，低频词，高频词过滤
	- 重视数据的特征工程：
	    - 常见的如n-gram，tf，idf，词性标注，句法依存，
	    - 文档中主题分散度：各种主题的糅杂在一起的是机器
	    - 语义相关性：各种主题语义的词柔和在一起是机器
	    - 文本内实体关联度等。
	- 重视对模型的选择：
	    - 考虑使用深度模型，CNN、RNN、LSTM等
	    - 强烈建议使用这个，不然使用传统的svm或者xgboost等特征工程的方法，很浪费调参、等时间。
3. 其他人提示：
    - 用训练集的正样本，LDA分主题，再随机拼贴插入同主题其他文章的句子，机器效果更好
    - nlp的gan没那么好：
        - gan
        - seq2seq：直接生成部分
    - 多观察数据：的某些特点，比如词等？
        - 正
        - 负
    - 0.97：
 	+ cnn ＋ BN（batchnormaliztion） ＋ dropout ＋ 预训练词向量
 	+ gensim 的 word2vec，把训练集和测试集的预料都用上
 	+ titanX下：网络参数不用太多，也不要很多层。先调到能过拟合，再慢慢加正则。一个小时就差不多了
    - 启发：
    	+ 通过拼接句子构造负样本，然后识别区分人机的nlp任务
    - 结巴：
    	+ 结巴分完词后解决100w，选词频前20w，其余的直接扔掉，不然按unknown处理会加大内存消耗
    - 正则：
    	+ 直接利用正则表达式找负样本的特征
    	+ 比如ab+这个表达式描述了特征是一个a和任意个b的特征字串
    
    - 为了找到最优的过滤器(Filter)大小，可以使用线性搜索的方法。通常过滤器的大小范围在1-10之间，当然对于长句，使用更大的过滤器也是有必要的
    - Feature Map的数量在100-600之间；
    - 可以尽量多尝试激活函数，实验发现ReLU和tanh两种激活函数表现较佳
    - 使用简单的1-max pooling就已经足够了，可以没必要设置太复杂的pooling方式
    - 当发现增加Feature Map的数量使得模型的性能下降时，可以考虑增大正则的力度，如调高dropout的概率
    - 为了检验模型的性能水平，多次反复的交叉验证是必要的，这可以确保模型的高性能并不是偶然


3. 优化：
    - 使用已有的文本自行生成词向量
    - 给jieba词典添加一些常用的词典
    - 加入文本特征的规则阈值ifelse
    - 加入svm、xgboost等混合模型
    - 加入nlp
    - 具体特征：
        + 题目
        + 内容：
            - 标点问题
            - 语义连贯性
            - 不要去停用词，这样就破坏特征了，有的机器写的还会有语法错误
            - 长度：机器人一不小心就会写很长。。。：字数和句子数
            - 关于长短文本的处理：
            	+ 直接补齐最长的不可能，内存不允许，也容易过拟合
            	+ 将长句子切割为多个子句单元，最后输出的时候整合，或者在网络中间整合为一个输出。
            - 特殊长度：
            	+ 如果文本太长，检查是否包含大量字母，包含，则为Negative
            	+ 
        + 生成来源：
            - 很多句子应该是从其他文章中放进去的，应该不是从词单位来生成文章。
            - 所以直接针对某个局部的句子是看不出来的，那么就可以通过jieba分词，选取词频前多少的词进行词向量的建立
            


